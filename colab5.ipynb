{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3Afy9c2++LlAIA0Ju5FN8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "234635e28a6d4e43a911d854d87ec944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43a8de6488c44d6690ff26af14d24acf",
              "IPY_MODEL_f0b2d1e11b3d49529adfebba8d65f164",
              "IPY_MODEL_0fd039b05bc14aefa87cd20089649d94"
            ],
            "layout": "IPY_MODEL_05a08007451546c6a5bbfc5fcc0f0a21"
          }
        },
        "43a8de6488c44d6690ff26af14d24acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b963b056a24c0292c96cdc1e94cc4e",
            "placeholder": "​",
            "style": "IPY_MODEL_bafe10a65a724997a44c9b2f54da63d2",
            "value": "Generating train split: "
          }
        },
        "f0b2d1e11b3d49529adfebba8d65f164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_413cdc0a913d42dfb92de9f57268ff3f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d347cd1a6c54df09c0581d9a04ce4fc",
            "value": 1
          }
        },
        "0fd039b05bc14aefa87cd20089649d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ca95cc62f3c4a9498e8b65aabddb7bd",
            "placeholder": "​",
            "style": "IPY_MODEL_1caaa6ced95941d589d43f15283eaca4",
            "value": " 1000/0 [00:00&lt;00:00, 67608.63 examples/s]"
          }
        },
        "05a08007451546c6a5bbfc5fcc0f0a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b963b056a24c0292c96cdc1e94cc4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bafe10a65a724997a44c9b2f54da63d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "413cdc0a913d42dfb92de9f57268ff3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2d347cd1a6c54df09c0581d9a04ce4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ca95cc62f3c4a9498e8b65aabddb7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1caaa6ced95941d589d43f15283eaca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cafed5595c40435ba4af5d9511d3f66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9004f417424745989733075c4aa2f102",
              "IPY_MODEL_12a1b2dd9e854fc7980b6949f2c6073b",
              "IPY_MODEL_6669607f3ad942e582707e22ed250401"
            ],
            "layout": "IPY_MODEL_851bbcfbcb014ecc8d361d054619f08b"
          }
        },
        "9004f417424745989733075c4aa2f102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da6f0d52b39476ea2382ff5809e2bf6",
            "placeholder": "​",
            "style": "IPY_MODEL_c7deabacf93f4ea3a1858c1a62cb5fe5",
            "value": "Map: 100%"
          }
        },
        "12a1b2dd9e854fc7980b6949f2c6073b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_382fdf4e6ec743939de521cfedfff6a2",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b897c594539d48db8aaa8a58187ba54f",
            "value": 1000
          }
        },
        "6669607f3ad942e582707e22ed250401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8042375db19a4e8c8716a9517a48be53",
            "placeholder": "​",
            "style": "IPY_MODEL_841104f6a5e849e7b86a57a2dca7cc68",
            "value": " 1000/1000 [00:00&lt;00:00, 22861.10 examples/s]"
          }
        },
        "851bbcfbcb014ecc8d361d054619f08b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da6f0d52b39476ea2382ff5809e2bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7deabacf93f4ea3a1858c1a62cb5fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "382fdf4e6ec743939de521cfedfff6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b897c594539d48db8aaa8a58187ba54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8042375db19a4e8c8716a9517a48be53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "841104f6a5e849e7b86a57a2dca7cc68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "822ad02d04b64cee9107c870305b81ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0a28623242a4122a4a25b5180014fdc",
              "IPY_MODEL_4b423866611445898f15381b9f2f3423",
              "IPY_MODEL_7fb37f027aab4589898e4f975d3001f5"
            ],
            "layout": "IPY_MODEL_70237316f1c14705a7c4a6c3f1243833"
          }
        },
        "a0a28623242a4122a4a25b5180014fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbb11c449a8e4d7299368a0a8fcc313f",
            "placeholder": "​",
            "style": "IPY_MODEL_be19ce554a00490e9d78060fe52f1121",
            "value": "Tokenizing: 100%"
          }
        },
        "4b423866611445898f15381b9f2f3423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e79fb391f282404e96a0332be313167e",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca1adfeb062c4369b55ded7b7ea138cf",
            "value": 1000
          }
        },
        "7fb37f027aab4589898e4f975d3001f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e6806e555154433bb1a7113d52b9ae1",
            "placeholder": "​",
            "style": "IPY_MODEL_f18a0cf8285d42f3a1db55c39f53ebc2",
            "value": " 1000/1000 [00:00&lt;00:00, 22239.39 examples/s]"
          }
        },
        "70237316f1c14705a7c4a6c3f1243833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbb11c449a8e4d7299368a0a8fcc313f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be19ce554a00490e9d78060fe52f1121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e79fb391f282404e96a0332be313167e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca1adfeb062c4369b55ded7b7ea138cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e6806e555154433bb1a7113d52b9ae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f18a0cf8285d42f3a1db55c39f53ebc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darshlukkad/Unsloth/blob/main/colab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRhDJLw-WnaL",
        "outputId": "1fee4b33-4b19-43b6-f72b-87339f19c5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "Torch: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "Mon Nov 10 07:06:26 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0             34W /   70W |     432MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "dtype: torch.float16 | device: cuda\n"
          ]
        }
      ],
      "source": [
        "# --- Install deps (Colab) ---\n",
        "%pip -q install -U unsloth transformers datasets accelerate peft bitsandbytes einops evaluate sentencepiece\n",
        "\n",
        "# --- Stability flags BEFORE importing transformers/trl/peft ---\n",
        "import os, sys, platform, torch, subprocess\n",
        "os.environ[\"UNSLOTH_COMPILE_DISABLE\"] = \"1\"   # avoid flaky compiled kernels on some Colab builds\n",
        "os.environ[\"UNSLOTH_STABLE_DOWNLOADS\"] = \"1\"  # quieter, more robust HF downloads\n",
        "\n",
        "# Import Unsloth FIRST so it can patch transformers properly\n",
        "import unsloth\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "\n",
        "# Now the rest\n",
        "from datasets import load_dataset\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "\n",
        "# Basic env printouts\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "!nvidia-smi || echo \"No NVIDIA GPU detected\"\n",
        "\n",
        "# Precision & common constants\n",
        "dtype = torch.bfloat16 if is_bfloat16_supported() else torch.float16\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MAX_SEQ_LEN = 2048     # model context\n",
        "BLOCK_SIZE  = 512      # training sequence length\n",
        "print(\"dtype:\", dtype, \"| device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Policy for continued pretraining: 4-bit base + LoRA (also adapt embeddings & lm_head)\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "model_id = \"HuggingFaceTB/SmolLM2-135M\"\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name      = model_id,\n",
        "    max_seq_length  = MAX_SEQ_LEN,   # from Cell 1\n",
        "    dtype           = dtype,          # from Cell 1\n",
        "    load_in_4bit    = True,           # QLoRA style for low VRAM\n",
        ")\n",
        "\n",
        "# Include embeddings & lm_head so the model can better absorb new-language tokens\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r                          = 16,\n",
        "    lora_alpha                 = 16,\n",
        "    lora_dropout               = 0.05,\n",
        "    target_modules             = [\n",
        "        \"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\n",
        "        \"gate_proj\",\"up_proj\",\"down_proj\",\n",
        "        \"embed_tokens\",\"lm_head\"      # <- important for CPT\n",
        "    ],\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state               = 3407,\n",
        "    max_seq_length             = MAX_SEQ_LEN,\n",
        ")\n",
        "\n",
        "# Tokenizer safety defaults\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# Show how many parameters will be trained via LoRA\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Loaded: {model_id}\")\n",
        "print(f\"Device: {model.device} | 4-bit: True\")\n",
        "print(f\"Trainable params: {trainable_params/1e6:.2f}M / {total_params/1e6:.2f}M \"\n",
        "      f\"({100*trainable_params/total_params:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOMHLKoxYe5b",
        "outputId": "e9120503-673f-4c09-a46e-f2851a03a107"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.11.2: Fast Llama patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "HuggingFaceTB/SmolLM2-135M does not have a padding token! Will use pad_token = <|endoftext|>.\n",
            "Unsloth: Offloading input_embeddings to disk to save VRAM\n",
            "Unsloth: Offloading output_embeddings to disk to save VRAM\n",
            "Unsloth: Training embed_tokens in mixed precision to save VRAM\n",
            "Unsloth: Training lm_head in mixed precision to save VRAM\n",
            "Loaded: HuggingFaceTB/SmolLM2-135M\n",
            "Device: cpu | 4-bit: True\n",
            "Trainable params: 61.51M / 171.25M (35.92%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust Yoruba (yor) corpus loader from Tatoeba using iter_lines (no scripts/auth)\n",
        "import os, re, random, requests\n",
        "from datasets import load_dataset\n",
        "\n",
        "def normalize(s: str) -> str:\n",
        "    if s is None: return \"\"\n",
        "    s = s.replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "TATOEBA_URL = \"https://downloads.tatoeba.org/exports/sentences.csv\"\n",
        "MAX_KEEP    = 100_000     # upper bound of lines to keep from stream\n",
        "MIN_CHARS   = 20          # filter very short lines\n",
        "FALLBACK_MIN = 1000       # if we get fewer than this, use a tiny fallback\n",
        "corpus_path = \"corpora/yoruba_tatoeba.txt\"\n",
        "os.makedirs(\"corpora\", exist_ok=True)\n",
        "\n",
        "yor_lines = []\n",
        "try:\n",
        "    with requests.get(TATOEBA_URL, stream=True, timeout=180) as r:\n",
        "        r.raise_for_status()\n",
        "        # Each line is \"id<TAB>lang<TAB>text\"\n",
        "        for line in r.iter_lines(decode_unicode=True):\n",
        "            if not line:\n",
        "                continue\n",
        "            parts = line.split(\"\\t\", 2)\n",
        "            if len(parts) < 3:\n",
        "                continue\n",
        "            _id, lang, text = parts[0], parts[1], parts[2]\n",
        "            if lang == \"yor\":\n",
        "                t = normalize(text)\n",
        "                if len(t) >= MIN_CHARS:\n",
        "                    yor_lines.append(t)\n",
        "                    if len(yor_lines) >= MAX_KEEP:\n",
        "                        break\n",
        "    print(f\"Streamed Yoruba lines: {len(yor_lines)}\")\n",
        "except Exception as e:\n",
        "    print(\"Tatoeba stream failed:\", e)\n",
        "\n",
        "# Minimal fallback so the notebook can proceed even if the stream is blocked\n",
        "if len(yor_lines) < FALLBACK_MIN:\n",
        "    seed = [\n",
        "        \"Báwo ni o ṣe wà?\", \"Mo wà dáadáa, ẹ ṣé.\", \"Orúkọ mi ni Ade.\",\n",
        "        \"Ìfẹ́ ni ìmúṣẹ gbogbo ohun rere.\", \"A ń kọ́ èdè Yorùbá.\",\n",
        "        \"Ìwe yìí dára gan-an.\", \"Ṣe o lè ràn mí lọ́wọ́?\", \"Ó ṣeun gan-an.\",\n",
        "        \"Ọjọ́ mẹ́ta ni mo ní kí n pé níbí.\", \"Gbọ́dọ̀ kọ́ ẹ̀kọ́ lojoojúmọ́.\"\n",
        "    ]\n",
        "    mult = FALLBACK_MIN // len(seed) + 1\n",
        "    yor_lines = (seed * mult)[:FALLBACK_MIN]\n",
        "    print(f\"Using fallback mini-corpus with {len(yor_lines)} lines.\")\n",
        "\n",
        "# Write corpus (one sentence per line)\n",
        "with open(corpus_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in yor_lines:\n",
        "        f.write(line + \"\\n\")\n",
        "print(f\"Saved Yoruba corpus to {corpus_path}\")\n",
        "\n",
        "# Load as a plain text dataset and standardize to 'text'\n",
        "raw = load_dataset(\"text\", data_files=corpus_path, split=\"train\")\n",
        "raw = raw.rename_column(\"text\", \"raw_text\")\n",
        "ds = raw.map(lambda ex: {\"text\": normalize(ex[\"raw_text\"])}, remove_columns=[\"raw_text\"])\n",
        "\n",
        "# Optional cap for quick demo; increase for better CPT\n",
        "MAX_SAMPLES = 20_000\n",
        "if len(ds) > MAX_SAMPLES:\n",
        "    random.seed(42)\n",
        "    idxs = list(range(len(ds)))\n",
        "    random.shuffle(idxs)\n",
        "    ds = ds.select(idxs[:MAX_SAMPLES])\n",
        "\n",
        "print(\"Cleaned examples:\", len(ds))\n",
        "print(\"\\nSample text:\\n\", ds[0][\"text\"][:200], \" …\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206,
          "referenced_widgets": [
            "234635e28a6d4e43a911d854d87ec944",
            "43a8de6488c44d6690ff26af14d24acf",
            "f0b2d1e11b3d49529adfebba8d65f164",
            "0fd039b05bc14aefa87cd20089649d94",
            "05a08007451546c6a5bbfc5fcc0f0a21",
            "a6b963b056a24c0292c96cdc1e94cc4e",
            "bafe10a65a724997a44c9b2f54da63d2",
            "413cdc0a913d42dfb92de9f57268ff3f",
            "2d347cd1a6c54df09c0581d9a04ce4fc",
            "8ca95cc62f3c4a9498e8b65aabddb7bd",
            "1caaa6ced95941d589d43f15283eaca4",
            "cafed5595c40435ba4af5d9511d3f66b",
            "9004f417424745989733075c4aa2f102",
            "12a1b2dd9e854fc7980b6949f2c6073b",
            "6669607f3ad942e582707e22ed250401",
            "851bbcfbcb014ecc8d361d054619f08b",
            "4da6f0d52b39476ea2382ff5809e2bf6",
            "c7deabacf93f4ea3a1858c1a62cb5fe5",
            "382fdf4e6ec743939de521cfedfff6a2",
            "b897c594539d48db8aaa8a58187ba54f",
            "8042375db19a4e8c8716a9517a48be53",
            "841104f6a5e849e7b86a57a2dca7cc68"
          ]
        },
        "id": "HuA0Ri4TjtpY",
        "outputId": "ddfbdb0c-4ecf-453c-d57b-c5353cfbd59a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tatoeba stream failed: a bytes-like object is required, not 'str'\n",
            "Using fallback mini-corpus with 1000 lines.\n",
            "Saved Yoruba corpus to corpora/yoruba_tatoeba.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "234635e28a6d4e43a911d854d87ec944"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cafed5595c40435ba4af5d9511d3f66b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned examples: 1000\n",
            "\n",
            "Sample text:\n",
            " Báwo ni o ṣe wà?  …\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the Yorùbá corpus and pack into contiguous BLOCK_SIZE chunks\n",
        "from datasets import Dataset\n",
        "import math\n",
        "\n",
        "assert \"ds\" in globals(), \"Dataset `ds` not found. Run the corpus cell first.\"\n",
        "assert \"BLOCK_SIZE\" in globals(), \"BLOCK_SIZE not defined. Check Cell 1.\"\n",
        "\n",
        "# Ensure we have an EOS / PAD token id for clean boundaries between lines\n",
        "eos_id = tokenizer.eos_token_id or tokenizer.pad_token_id\n",
        "assert eos_id is not None, \"Tokenizer needs an eos_token_id or pad_token_id.\"\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    # Fast batch tokenization; no truncation (we'll pack manually)\n",
        "    toks = tokenizer(batch[\"text\"], add_special_tokens=False)\n",
        "    # Append EOS per sample to separate lines when packing\n",
        "    toks[\"input_ids\"] = [ids + [eos_id] for ids in toks[\"input_ids\"]]\n",
        "    return {\"input_ids\": toks[\"input_ids\"]}\n",
        "\n",
        "# Tokenize (batched) and keep only token ids\n",
        "tok = ds.map(tokenize_fn, batched=True, remove_columns=ds.column_names, desc=\"Tokenizing\")\n",
        "\n",
        "# Manual packer to avoid giant concatenations\n",
        "packed_input_ids = []\n",
        "packed_attention = []\n",
        "packed_labels    = []\n",
        "\n",
        "buf = []\n",
        "for ids in tok[\"input_ids\"]:\n",
        "    buf.extend(ids)\n",
        "    while len(buf) >= BLOCK_SIZE:\n",
        "        chunk = buf[:BLOCK_SIZE]\n",
        "        packed_input_ids.append(chunk)\n",
        "        packed_attention.append([1] * BLOCK_SIZE)\n",
        "        packed_labels.append(chunk.copy())   # LM labels = input_ids\n",
        "        buf = buf[BLOCK_SIZE:]\n",
        "\n",
        "num_blocks = len(packed_input_ids)\n",
        "if num_blocks == 0:\n",
        "    raise RuntimeError(\"No packed blocks created. Try lowering BLOCK_SIZE or increasing dataset size.\")\n",
        "\n",
        "packed_ds = Dataset.from_dict(\n",
        "    {\"input_ids\": packed_input_ids, \"attention_mask\": packed_attention, \"labels\": packed_labels}\n",
        ")\n",
        "\n",
        "# Quick report\n",
        "total_tokens = num_blocks * BLOCK_SIZE\n",
        "approx_epochs_1k_steps = (total_tokens / BLOCK_SIZE) / 1000.0\n",
        "print(f\"Packed {num_blocks} blocks of {BLOCK_SIZE} tokens each \"\n",
        "      f\"(~{total_tokens:,} tokens).\")\n",
        "print(\"Example decode (first 200 chars):\\n\",\n",
        "      tokenizer.decode(packed_input_ids[0], skip_special_tokens=True)[:200], \"…\")\n",
        "\n",
        "# For training later\n",
        "train_cpt = packed_ds\n",
        "len(train_cpt), train_cpt[0][\"input_ids\"][:8]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "822ad02d04b64cee9107c870305b81ea",
            "a0a28623242a4122a4a25b5180014fdc",
            "4b423866611445898f15381b9f2f3423",
            "7fb37f027aab4589898e4f975d3001f5",
            "70237316f1c14705a7c4a6c3f1243833",
            "dbb11c449a8e4d7299368a0a8fcc313f",
            "be19ce554a00490e9d78060fe52f1121",
            "e79fb391f282404e96a0332be313167e",
            "ca1adfeb062c4369b55ded7b7ea138cf",
            "1e6806e555154433bb1a7113d52b9ae1",
            "f18a0cf8285d42f3a1db55c39f53ebc2"
          ]
        },
        "id": "CVDLmG-KdxLi",
        "outputId": "67648212-5a7a-4679-8e8b-047501c7d77f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "822ad02d04b64cee9107c870305b81ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Packed 38 blocks of 512 tokens each (~19,456 tokens).\n",
            "Example decode (first 200 chars):\n",
            " Báwo ni o ṣe wà?Mo wà dáadáa, ẹ ṣé.Orúkọ mi ni Ade.Ìfẹ́ ni ìmúṣẹ gbogbo ohun rere.A ń kọ́ èdè Yorùbá.Ìwe yìí dára gan-an.Ṣe o lè ràn mí lọ́wọ́?Ó ṣeun gan-an.Ọjọ́ mẹ́ta ni mo ní kí n pé níbí.Gbọ́dọ̀ kọ …\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, [50, 5415, 6466, 39112, 263, 216, 27840, 85])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continued pretraining on Yoruba blocks (causal LM objective, LoRA adapters)\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "import torch, math\n",
        "\n",
        "assert \"train_cpt\" in globals(), \"Packed dataset `train_cpt` not found. Run Cell 4 first.\"\n",
        "\n",
        "# Causal LM data collator (labels already prepared, but harmless to pass mlm=False)\n",
        "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Some models need cache off during training\n",
        "if hasattr(model.config, \"use_cache\"):\n",
        "    model.config.use_cache = False\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"outputs_cpt_yoruba_smollm2\",\n",
        "    per_device_train_batch_size=8,      # if OOM on T4, try 4 or 2\n",
        "    gradient_accumulation_steps=1,\n",
        "    num_train_epochs=1,                 # increase for better adaptation\n",
        "    learning_rate=1e-4,                 # CPT often uses 5e-5 ~ 2e-4; tune as needed\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.03,\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\",\n",
        "    fp16=True,                          # T4 prefers fp16\n",
        "    bf16=False,\n",
        "    optim=\"adamw_bnb_8bit\",             # 8-bit optimizer (bitsandbytes)\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_cpt,\n",
        "    data_collator=collator,\n",
        ")\n",
        "\n",
        "train_out = trainer.train()\n",
        "print(\"CPT training complete.\")\n",
        "print(train_out)\n",
        "\n",
        "# Save ONLY the LoRA adapter (compact) + tokenizer for convenience\n",
        "adapter_dir = \"smollm2_cpt_yoruba_adapter\"\n",
        "trainer.model.save_pretrained(adapter_dir)\n",
        "tokenizer.save_pretrained(adapter_dir)\n",
        "print(\"Saved CPT LoRA adapter ->\", adapter_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "_rA0nc6vmetq",
        "outputId": "3e999eba-5b82-4f24-9991-543505eb77d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n",
            "   \\\\   /|    Num examples = 38 | Num Epochs = 1 | Total steps = 5\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 1 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 61,507,584 of 224,334,144 (27.42% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:04, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n",
            "CPT training complete.\n",
            "TrainOutput(global_step=5, training_loss=1.7551740646362304, metrics={'train_runtime': 11.5193, 'train_samples_per_second': 3.299, 'train_steps_per_second': 0.434, 'total_flos': 19577915965440.0, 'train_loss': 1.7551740646362304, 'epoch': 1.0})\n",
            "Saved CPT LoRA adapter -> smollm2_cpt_yoruba_adapter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean reload for inference: base (4-bit) + CPT LoRA adapter; generate Yorùbá text\n",
        "import os, torch, textwrap\n",
        "from unsloth import FastLanguageModel\n",
        "from peft import PeftModel\n",
        "\n",
        "base_id     = \"HuggingFaceTB/SmolLM2-135M\"\n",
        "adapter_dir = \"smollm2_cpt_yoruba_adapter\"\n",
        "assert os.path.isdir(adapter_dir), \"Adapter folder not found. Run the CPT training cell first.\"\n",
        "\n",
        "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "# 1) Reload base model in 4-bit for low-VRAM inference\n",
        "base_model, tok = FastLanguageModel.from_pretrained(\n",
        "    model_name     = base_id,\n",
        "    max_seq_length = 2048,\n",
        "    dtype          = dtype,\n",
        "    load_in_4bit   = True,\n",
        ")\n",
        "\n",
        "# 2) Attach LoRA adapter (continued pretraining weights)\n",
        "model = PeftModel.from_pretrained(base_model, adapter_dir)\n",
        "model.eval()\n",
        "\n",
        "# 3) Tokenizer safety defaults\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "tok.padding_side = \"right\"\n",
        "\n",
        "device = model.device\n",
        "\n",
        "def generate(prompt, max_new_tokens=160, temperature=0.8, top_p=0.95):\n",
        "    inputs = tok(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            pad_token_id=tok.eos_token_id,\n",
        "        )\n",
        "    return tok.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "# 4) Yorùbá prompts to sanity-check adaptation\n",
        "prompts = [\n",
        "    # Short greeting\n",
        "    \"Kọ ìbáṣepọ̀ kíkan ní èdè Yorùbá fún olùkọ́ tuntun kan ní kilasì.\",\n",
        "    # Tiny story\n",
        "    \"Kọ ìtàn kékeré ní èdè Yorùbá nípa ọmọkùnrin kan tí ó kọ́ ẹ̀kọ́ bí a ṣe ń kọ orin bàtá.\",\n",
        "    # Informational paragraph\n",
        "    \"Ṣàlàyé ní kíkún ní èdè Yorùbá pé kí ni ìtọju ilera ọpọlọ, àti àwọn ìmòràn mẹ́ta fún ìdènà aapọn.\"\n",
        "]\n",
        "\n",
        "for i, p in enumerate(prompts, 1):\n",
        "    print(f\"\\n=== Prompt {i} ===\\n{p}\\n\")\n",
        "    text = generate(p)\n",
        "    # Show only the continuation (since we don't template chat here)\n",
        "    print(\"=== Output ===\\n\" + textwrap.fill(text, width=100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEB1vVhOmmOv",
        "outputId": "b84deaae-8589-4036-a364-6ff5323ec8fc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.11.2: Fast Llama patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "HuggingFaceTB/SmolLM2-135M does not have a padding token! Will use pad_token = <|endoftext|>.\n",
            "\n",
            "=== Prompt 1 ===\n",
            "Kọ ìbáṣepọ̀ kíkan ní èdè Yorùbá fún olùkọ́ tuntun kan ní kilasì.\n",
            "\n",
            "=== Output ===\n",
            "Kọ ìbáṣepọ̀ kíkan ní èdè Yorùbá fún olùkọ́ tuntun kan ní kilasì.  KiẴ tím chuộng tím đời, chiứn kíp\n",
            "bị tím.  KiẴ kíp kíp súa môsì.  KiẴ kíp kíp čík tím ẩọmọn kípọ̀ kípọ̀ môsì.  KiẴ kíp kíp kíp čík\n",
            "kípọ̀ kípọ̀ kípọ̀ môsì.  KiẴ kíp kí\n",
            "\n",
            "=== Prompt 2 ===\n",
            "Kọ ìtàn kékeré ní èdè Yorùbá nípa ọmọkùnrin kan tí ó kọ́ ẹ̀kọ́ bí a ṣe ń kọ orin bàtá.\n",
            "\n",
            "=== Output ===\n",
            "Kọ ìtàn kékeré ní èdè Yorùbá nípa ọmọkùnrin kan tí ó kọ́ ẹ̀kọ́ bí a ṣe ń kọ orin bàtá. än êr tú kọ\n",
            "mọ kọ kéner. än êr tú kọ mọ kọ kéner. än êr tú kọ mọ kọ kéner. än êr tú kọ mọ kọ kéner. än êr tú kọ\n",
            "mọ kọ kéner. än êr tú kọ mọ kọ kéner. än êr tú kọ mọ kọ kéner. än êr tú kọ m�\n",
            "\n",
            "=== Prompt 3 ===\n",
            "Ṣàlàyé ní kíkún ní èdè Yorùbá pé kí ni ìtọju ilera ọpọlọ, àti àwọn ìmòràn mẹ́ta fún ìdènà aapọn.\n",
            "\n",
            "=== Output ===\n",
            "Ṣàlàyé ní kíkún ní èdè Yorùbá pé kí ni ìtọju ilera ọpọlọ, àti àwọn ìmòràn mẹ́ta fún ìdènà aapọn. Ví,\n",
            "hìn ní kíkún ní ìmòràn kímì kíi. Ví ìmòràn ìmòràn kí mèn kí ní ìní ìmòràn ìmòràn ní ìmòràn ìmòràn\n",
            "ìmòràn ìmòràn ìmòràn ìmòràn ìmòràn ìmòràn ìmòràn ìmòràn ìmòràn ìmòràn �\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tWNvKnSHmxmd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}